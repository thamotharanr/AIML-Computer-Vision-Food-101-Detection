{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3085fdd",
   "metadata": {},
   "source": [
    "# AIML Computer Vision : Capstone Project - Food 101 Detection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac1c33",
   "metadata": {},
   "source": [
    "## PROBLEM STATEMENT\n",
    "\n",
    "### DOMAIN: Food Industry\n",
    "\n",
    "Can you generate proper business level details on Context, Data Description and Project Objective based on below details.\n",
    "\n",
    "### CONTEXT: \n",
    "In the era of digital transformation, automated food detection using computer vision has become increasingly important in various sectors such as hospitality, healthcare, fitness, retail, and food delivery. Accurate identification of food items from images enables intelligent systems to recognize what a person is eating, streamline restaurant operations, or even automate checkout processes in cafeterias.\n",
    "\n",
    "For example, in a smart cafeteria, cameras can detect and identify food items on a tray without manual input, enabling a frictionless billing experience. In diet and nutrition apps, users can take a picture of their meal, and the app can instantly classify the food and estimate nutritional content. In quality assurance for food production, automated systems can detect if the right type of food is being processed or if items are visually defective.\n",
    "\n",
    "Such applications demand a robust food classification model capable of identifying food items from images with high accuracy, regardless of variations in presentation, lighting, or camera angles. This project aims to tackle this challenge by leveraging deep learning techniques to train a model that can automatically detect and classify different types of food from a diverse dataset of labeled food images.\n",
    "\n",
    "### DATA DESCRIPTION:\n",
    "\n",
    "The project uses a curated subset of the Food-101 dataset, a widely used benchmark for food classification tasks. This dataset includes:\n",
    "\n",
    "500 images categorized into\n",
    "\n",
    "10 distinct food classes (e.g., apple_pie, fried_rice, sushi)\n",
    "\n",
    "Each class contains a balanced distribution of training and test images, generally split in a 70-30 ratio\n",
    "\n",
    "Images vary in lighting, background, and angle to mimic real-world food photography conditions\n",
    "\n",
    "Each image is labeled with the corresponding food class, enabling supervised learning approaches to be applied effectively.\n",
    "\n",
    "\n",
    "### PROJECT OBJECTIVE: \n",
    "**The primary goal of this project is to:**\n",
    "\n",
    "Develop a deep learning-based food identification model that can accurately classify food items from images.\n",
    "\n",
    "**Key objectives include:**\n",
    "\n",
    "Building a convolutional neural network (CNN) model to classify food images into one of the 10 defined categories\n",
    "\n",
    "Evaluating model performance using standard metrics such as accuracy, precision, recall and confusion matrix.\n",
    "\n",
    "Enabling a potential real-time application where the trained model can be integrated into camera-based systems for smart kitchens, restaurant automation, or diet-tracking apps\n",
    "\n",
    "Ultimately, this solution aims to demonstrate the feasibility of intelligent, camera-driven food recognition systems, contributing toward innovations in food technology and AI-driven lifestyle tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f445c64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "789560f8",
   "metadata": {},
   "source": [
    "### Import the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c77bd2",
   "metadata": {},
   "source": [
    "#### Load all necessary libararies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc6606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, ZeroPadding2D,Flatten, Activation\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import Input for defining input shape\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e471b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMLCVCPFD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
